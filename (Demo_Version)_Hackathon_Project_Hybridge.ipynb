{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(Demo Version) Hackathon Project: Hybridge.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title We classified meetings into 7 types: Executive, Team, Design Discussion, Bug Scrub, Code Review, 1:1, and Daily Standup. Click to see our labeling scheme.\n",
        "'''\n",
        "Meeting type labeling scheme\n",
        "1 - Management/Executive\n",
        "2 - Team meeting\n",
        "3 - Design discussion\n",
        "4 - Bug scrub\n",
        "5 - Code review\n",
        "6 - 1:1\n",
        "7 - Daily standup\n",
        "'''"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aRXsk25YKXDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Let's get started! Run this cell to download and import the required packages.\n",
        "# Imports\n",
        "import pandas as pd # for dataframes\n",
        "import json # parse meeting data\n",
        "import numpy as np # testing classifier accuracy\n",
        "\n",
        "from sklearn.model_selection import train_test_split # split data\n",
        "from sklearn.feature_extraction.text import CountVectorizer # one-hot vectors for words\n",
        "from sklearn.feature_extraction.text import TfidfTransformer # calculate term frequencies\n",
        "from sklearn.naive_bayes import MultinomialNB # naive-bayes classifier\n",
        "from sklearn.linear_model import SGDClassifier # SVM classifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import nltk \n",
        "from nltk.corpus import stopwords # removing stopwords\n",
        "from nltk.tokenize import word_tokenize # splitting string into individual words\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RYf2eWnBK9vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Next, run this cell to answer some questions.\n",
        "print('Welcome to Hybridge command-line version!')\n",
        "TARGET_DATE = input('What date would you like to look at? Please enter in \\'M/D/YYYY\\' form.\\n(To fit our synthesized data, choose something between 8/1 and 8/28/2022!)')\n",
        "OFFICE_LIMIT = int(input('What\\'s the maximum in-person capacity of your office?'))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vwbvUs3lLcZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Great! Now run this cell to classify your meetings.\n",
        "# Function to convert list of strings to single string\n",
        "def listToString(l):\n",
        "  s = ''\n",
        "  for word in l:\n",
        "    if word is not l[len(l)-1]:\n",
        "        s += word + ' '\n",
        "    else:\n",
        "        s += word\n",
        "  return s\n",
        "\n",
        "# Load JSON object from file\n",
        "with open('meeting-data.json') as file:\n",
        "  j = json.load(file)\n",
        "\n",
        "# Normalize meetings object (flatten into columns)\n",
        "data = pd.json_normalize(j['meetings'])\n",
        "\n",
        "# Function to remove stopwords from row's description\n",
        "def remove_stopwords(row):\n",
        "  return listToString([word for word in word_tokenize(row['Headline']) if word not in stop_words])\n",
        "\n",
        "# Lowercase descriptions\n",
        "data['Headline'].str.lower()\n",
        "\n",
        "# Remove stop-words and create new column\n",
        "stop_words = set(stopwords.words('english'))\n",
        "data['headline-clean'] = data.apply(lambda row:remove_stopwords(row), axis=1)\n",
        "\n",
        "# Count-vectorize descriptions (one-hot encoding)\n",
        "count_vec = CountVectorizer()\n",
        "terms = count_vec.fit_transform(data['headline-clean'])\n",
        "\n",
        "# Apply TF-IDF (calculates term frequencies)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "terms_tfidf = tfidf_transformer.fit_transform(terms)\n",
        "\n",
        "# Add to dataframe\n",
        "data['headline-vectorized'] = terms_tfidf.tocoo().toarray().tolist()\n",
        "\n",
        "# Split into data/labels (x/y), then train/test\n",
        "x = data.drop('Label', axis=1)\n",
        "y = pd.DataFrame({'label':data['Label']})\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.5)\n",
        "\n",
        "# Fit Naive-Bayes Classifier\n",
        "nb = MultinomialNB()\n",
        "nb.fit(x_train['headline-vectorized'].tolist(), y_train['label'].tolist())\n",
        "\n",
        "# Predict and check accuracy\n",
        "preds = nb.predict(x_test['headline-vectorized'].tolist())\n",
        "mean = np.mean(preds == y_test['label'].tolist())\n",
        "\n",
        "# Recommendation system\n",
        "x_test['predicted-label'] = preds\n",
        "sorted_meetings = x_test.loc[(x_test['Date'] == TARGET_DATE)].sort_values(by='predicted-label') # Sort by selected date, priority (based on meeting type)\n",
        "\n",
        "in_person = 0\n",
        "count = 0\n",
        "for attendee_count in sorted_meetings['Attendee-count']:\n",
        "  if (in_person + attendee_count > OFFICE_LIMIT):\n",
        "    break\n",
        "  in_person += attendee_count\n",
        "  count += 1\n",
        "\n",
        "in_person_meetings = sorted_meetings.iloc[:count,:]\n",
        "remote_meetings = sorted_meetings.iloc[count:,:]\n",
        "\n",
        "print(\"Here are the meetings you had scheduled for \" + TARGET_DATE)\n",
        "sorted_meetings[['MeetingId', 'Headline', 'Date', 'Attendee-count', 'predicted-label']].style"
      ],
      "metadata": {
        "id": "9eA2CbagIr7Z",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell to see our suggestions for in-person meetings!\n",
        "print('Here\\'s the meetings we suggest you prioritize as in-person that day, based on your max occupancy of ' + str(OFFICE_LIMIT))\n",
        "in_person_meetings[['MeetingId', 'Headline', 'Date', 'Attendee-count', 'predicted-label']].style"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Z4IuQrRnN7hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this cell to see our suggestions for remote meetings!\n",
        "print('Here\\'s the meetings we suggest you leave as remote that day.')\n",
        "remote_meetings[['MeetingId', 'Headline', 'Date', 'Attendee-count', 'predicted-label']].style"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7pDEla-iOg6t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}